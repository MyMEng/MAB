%  
%  in CH1 give an real life example at the begining as a BACKGROOUND
%  describe bacis concepts
%  and go into more details? obvious
%  
%  
%  
%  in CH2 active learning or web optimization
%  
%  
%  
\documentclass[12pt, a4paper, pdflatex]{report}
%  notitlepage - abstract on the same page
\usepackage{indentfirst} % indent frst paragraph of section
\usepackage{fullpage} % full A4 page
\usepackage{amsmath}
\usepackage[pdftex]{graphicx}
\usepackage{cite} % BiTeX
\usepackage{lipsum}
\newcommand{\ts}{\textsuperscript}
\usepackage[usenames,dvipsnames]{color}

% \usepackage{polski}
% \usepackage[polish,english]{babel}
% \usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc} % polsih

\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}

\newenvironment{dedication}
  {\clearpage           % we want a new page
   \thispagestyle{empty}% no header and footer
   \vspace*{\stretch{1}}% some space at the top 
   \itshape             % the text is in italics
   \raggedleft          % flush to the right margin
  }
  {\par % end the paragraph
   \vspace{\stretch{3}} % space at bottom is three times that at the top
   \clearpage           % finish off the page
  }

\begin{document}

\begin{titlepage}
\begin{center}
% Upper part of the page. The '~' is needed because \\
% only works if a paragraph has started.
\includegraphics[width=0.5\textwidth]{graphics/UOB-logo.png}~\\[4cm] % was 1cm

% \textsc{\LARGE University of Bristol}\\[1.5cm]

%\textsc{\Large Final year project}\\[0.5cm]

% Title
\HRule \\[0.4cm]
{ \huge \bfseries \emph{Multi-armed bandits} problem.\\
	Comprehensive introduction to the \colorbox{magenta}{problem} for everyone with real life application. \\[0.4cm] }
\HRule \\[1.5cm]

% Author and supervisor
\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Author:}\\
Kacper \textsc{\textbf{Sokol}}
\end{flushleft}
\end{minipage}
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Supervisor:} \\
Dr.~David \textsc{\textbf{Leslie}}
\end{flushright}
\end{minipage}

\vfill

% Bottom of the page
{\large \today}
\end{center}
\end{titlepage}

% \title{\emph{Multi-armed bandits} problem.\\
% 	Practical introduction to the problem for everyone.\\
% 	Real life application.}
% \author{Kacper Sokol\\University of Bristol, UK}
% \date{\today}
% \maketitle
% \begin{flushright}
% Supervised by:\\
% \textbf{David Leslie}
% \end{flushright}
% \begin{center}
% \line(1,0){250}
% \end{center}

\begin{abstract}
This dissertation consists of two chapters. First one is a general introduction to theory underlying multi-armed bandits problem. Reader is assumed not to need any prior knowledge in the field, only basics of statistics and probability theory are required. Second chapter is a ...
\begin{center}
Keywords: \textbf{multi-armed, bandit, reinforcement, learning, ...}
\end{center}
\end{abstract}

\begin{dedication}
I would like to thank my parents who support me both financially and mentally. For the guidance and advice they are providing so I can make right choices through life and fulfill my dream of studying abroad.\\
It would also be a painful journey without my supervisor Dr.\ David Leslie who always served me with an advice how to ``read'' all the mathematical book to not get overwhelmed with heavy maths.\\
And finally, big thanks to I.\ and J.\ who always take care of my leisure time even though it always lacks.\\[2cm]
% \foreignlanguage{polish}{}
Dzi\k{e}kuj\k{e} mamo,\\
dzi\k{e}kuj\k{e} Tomek.
\end{dedication}

\newpage
\tableofcontents
\newpage

\chapter{Theory behind multi-armed bandits}
The \emph{multi-armed bandit} problem has been rapidly developing field of statistics and probability theory since early 20\ts{th} century. With a vastly growing number of \colorbox{magenta}{problems} that could be framed as a multi-armed bandit scenario the has field become interest of many scientists and companies looking for savings and efficiency. All the solutions addressing this \colorbox{magenta}{problems} can be expressed as simple as finding a balance between \emph{exploration} and \emph{exploitation}.

\section{Background}
To encourage reader this section presents every-day life examples with underlying bandits theory. To begin with, \emph{fruit machine} is considered as it is a first thing that crosses reader's mind after reading title.\\
Imagine a row of slot machines in front of you. Pulling arm of each of this automaton will have different result that for now on can be interpreted as various reels combinations. For space efficiency imagine there is only one machine but with multiples arms or buttons each corresponding to single automaton in a row. If you do not want to loose all your money really quick it would probably be a good idea to have some kind of strategy that maximizes chances of winning. As you do not have any prior information regarding expected return from each of the arm you initially choose it at random. On contrary during second round you are facing serious dilemma that you might not yet realized. You can either choose the arm with known expected return because you have just pulled it (this action is  usually called \emph{exploitation}) or you can take a risk and choose unknown one to gather some information about the system (this step has a name of \emph{exploration}).
% zmien opis tak zeby to byly binarne maszyny win|loose z roznym pradopodobienstwem.

\section{Applications}
As mentioned before, there are multiple real-life applications ranging from drug testing and web advertisement income optimization through semi-supervised machine learning in modern computer science and time and budget management.

The second mentioned approach was implemented by Microsoft research group(DAJ REFERENCJE).

Blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah blah.

\section{Terminology}
It is very useful to be familiar with all the terminology used in multi-armed bandit papers and books. The basics concepts are listed below.
\begin{itemize}
\item Agent--- a person that decide what arm to pull based on $\tau$ function.\\
\item Multi-armed bandit($N$)--- a ``device'' with $N$ possible choices of action.~\cite{berry+firstedt}\\
\item Strategy ($\tau$)--- tells the player which arm to pull at given stage of game.\\
\item Game--- a sequence of arms pulled based on chosen strategy $\tau$.\\
\item Play--- a single arm pull at stage $m$ of the game.
\end{itemize}

\section{General assumptions}
\lipsum[1]

\section{Discount Sequence}
To specify the rules governing the ``significance'' of outcome from a single play at stage $m$ the \emph{discount sequence} is introduced. It is a vector $\mathbf{A}$ of specified length, which can also be infinite.
$$
\mathbf{A} = \left( \alpha_1, \alpha_2, \alpha_3, ... \right)
$$

\subsection{Observable and non-observable sequences}
\lipsum[1]

\subsection{Most common sequences}
There are many different discount sequences used with multi-armed bandits each with numerous assumptions. In the literature only two of them are described in great detail and both are presented below.
\subsubsection{Uniform sequence}
The $n$-horizon uniform discount sequence is defined as:
\[
 \alpha_i =
  \begin{cases}
   1 & \text{for } i \leq n \\
   0 & \text{for } i > n
  \end{cases}
\]
leading to:
\[
  \mathbf{A} = ( \underbrace{ 1, 1, 1, ..., 1}_{n\text{ elements}}, 0, 0, 0, ... ) \text{ .}
\]
\subsubsection{Geometric sequence}
The geometric discount sequence is expressed with components $\alpha_i = a^{i-1}$ for some $a \in ( 0, 1 )$ resulting in:
$$
\mathbf{A} = \left( a^0, a^1, a^2, ... \right)
$$
where $\alpha_1 = a^0$ is always equal to $1$.

\subsection{Non-monotone sequences}









\chapter{Practical application of multi-armed bandits algorithms}

\newpage
\begin{center} \textbf{\huge \vspace{15pt} FIN} \end{center}

\bibliography{ref}{}
\bibliographystyle{plain}

\end{document}
